---
layout: post
title: Baby Weight
comments: True
---
# Big Baby
When expecting a baby, ultrasounds are able to predict the weight of a baby, but they are known to be inacurate. 

Here I attempt to quantify the innacuracy and place a probability on a baby's birth weight. I found some interesting things along the way. 

## Assumptions

### Method of measurement
<https://pubmed.ncbi.nlm.nih.gov/30244476/>

There are a few different ways to estimate the current weight of a baby. The hadlock method seems best, here is an example formula:

>Hadlock 4: Log10 (weight) =1.3596 -0.00386* AC * FL+0.0064* HC+0.00061* BPD* AC+ 0.0424* AC+0.174*FL

* AC = Abdominal Circumfrence
* FL = Femur Length
* BPD = Biparietal Diameter (ear to ear distance)
* HC = Head Circumfrence

## The data set
I found a data set 
<https://www.kaggle.com/c/csci-ml-s19-pa1/data>
. It is difficult to pinpoint where this dataset came from but I was told it was real data from a hospital system. **Lets assume this data is garbage and everything about this is for the fun of Data Science and not actually informative**

## Code
Below is the chunk of code I used to analyze expected birthweights, feel free to skip over it if you have no intention of replicating this. 

    import os
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt


    def file_to_dataframe(file_name):
        """Makes a pandas table out of a specifically names file"""
        basepath = os.path.dirname(__file__)
        data_file = os.path.abspath(os.path.join(basepath, file_name + '.csv'))
        try:
            with open(data_file) as f:
                dataframe = pd.read_csv(f) # pd is pandas
            return dataframe
        except Exception as e:
            print(e)
            print('failed to read file')
            exit()


    def my_percentile(data, Value):
        """Give me data and a value and I will return the percentile of that value"""
        # To do this we sort the data then count the events below it
        sorted_data = sorted(data)
        lower = min(range(len(sorted_data)), key=lambda i: abs(sorted_data[i] - Value))
        rev_sorted_data = sorted(data, reverse=True)
        higher = min(range(len(rev_sorted_data)), key=lambda i: abs(rev_sorted_data[i] - Value))
        total = lower + higher
        percentile = lower / total
        return percentile


    if __name__ == "__main__":
        # Convert file to dataframe
        file_name = "baby-weights-dataset"
        main_dataframe = file_to_dataframe(file_name)
        print('Imported:')

        # Get the birth weights after week 37 before week 41
        expected_week_earliest = 37
        expected_week_latest = 41
        normal = main_dataframe.loc[main_dataframe['WEEKS'] >= expected_week_earliest]
        normal = normal.loc[main_dataframe['WEEKS'] <= expected_week_latest]

        # Compute frequency and bins
        frequency, bins = np.histogram(normal['BWEIGHT'], bins=50)

        # Max min
        normal = normal[np.abs(normal.BWEIGHT - normal.BWEIGHT.mean()) <= (3 * normal.BWEIGHT.std())]
        maximum = normal['BWEIGHT'].max()
        minimun = normal['BWEIGHT'].min()

        # Make the distribution
        x = normal['BWEIGHT']
        plt.hist(x, bins=50)
        frequency_plot = plt.gca().set(title='Frequency Histogram', ylabel='Frequency');
        plt.show(block=frequency_plot)
        plt.clf()

        # Predicted weight
        predicted_weight = 9.5

        # percentile calculator
        predicted_percentile = my_percentile(normal['BWEIGHT'], predicted_weight)

        # Tell
        print(
            f'A baby estimated at {predicted_weight}lb by the Hadlock Method baby is in the {predicted_percentile * 100:.2f} Percentile')

        # ten percent error
        min_weight = predicted_weight - .1 * predicted_weight
        max_weight = predicted_weight + .1 * predicted_weight

        predicted_min_percentile = my_percentile(normal['BWEIGHT'], min_weight)
        predicted_max_percentile = my_percentile(normal['BWEIGHT'], max_weight)

        less_range = predicted_percentile - predicted_min_percentile
        more_range = predicted_max_percentile - predicted_percentile

        less_percent = less_range / (less_range + more_range)
        more_percent = more_range / (less_range + more_range)

        # Tell
        print(
            f'Your baby is {less_percent * 100:.1f}% likely to be between {min_weight:.1f}lbs and {predicted_weight}lbs, but probably closer to {predicted_weight}')
        print(
            f'Your baby is {more_percent * 100:.1f}% likely to be between {predicted_weight}lbs and {max_weight:.1f}lbs but probably closer to {predicted_weight}')

        # lets check on likelyhood of birth injury
        # First lets squeeze down the window to the 10% range
        normal_avgs = normal.mean(axis=0)
        select = normal.loc[normal['BWEIGHT'] >= min_weight]
        select = select.loc[select['BWEIGHT'] <= max_weight]
        select_avgs = select.mean(axis=0)

        # Tell
        summary = normal_avgs.to_frame(name='norm').join(select_avgs.to_frame(name='Select'))
        pd.set_option("display.max_rows", None, "display.max_columns", None)
        print(summary.iloc[52:, :])

## Analysis
First off lets look at the distribution of births between 37 and 41 weeks of pregnancy (full term). Notice the discontinuity at the mean.

![Distribution](/images/BabyWeights.png)

Next lets look at the distribution from 0 weeks to 41 weeks.

![Distribution2](/images/BabyWeightsFull.png)

I have no idea why there seems to be a gap in baby weights around 7.5lbs when a baby is full term. I found that worth noting.

So next I put in 9.5 as the predicted baby weight and as expected this was the result:

>A baby estimated at 9.5lb by the Hadlock Method baby is in the 97.70 Percentile

>Your baby is 82.4% likely to be between 8.6lbs and 9.5lbs, but probably closer to 9.5

>Your baby is 17.6% likely to be between 9.5lbs and 10.4lbs but probably closer to 9.5

Because of regression to the mean, this makes sense. So if baby is predicted to be huge, most likely it is an overestimate. Likewise, if baby is predicted to be tiny most likely that is an underestimate as shown by these results from a 4.5lb estimate.

>A baby estimated at 4.5lb by the Hadlock Method baby is in the 3.87 Percentile

>Your baby is 38.6% likely to be between 4.0lbs and 4.5lbs, but probably closer to 4.5

>Your baby is 61.4% likely to be between 4.5lbs and 5.0lbs but probably closer to 4.5

**This is expected but rarely discussed in the doctors office.**

Finally, I compare the probability of different interventions and complications with regards to your babies size. 

Here are some interesting finds about small babies (4.5lbs) compared to average weight babies:
* Small babies have half the chance of ingesting meconium
* Small babies are twice as likely to be breech
* Small babies are less likely to need forceps or vacuum interventions

Here are some interesting finds about large babies (9.5lbs) compared to average weight babies:
* Large babies are slightly less likely to be breech
*  Large babies are slightly more likely to be born via C-Section
* Large babies are slightly less likely to be delivered with anesthesia

**These are all just correlations, and I have put absolutely no thought into the causes and effects of these, also remember this is not trustworthy data**

## Conclusion

There is definitely a lot more in the data that I did not summarize here. If you are expecting a baby and already have python setup I highly suggest playing around with this.

If anything this gave me and my wife comfort that the average baby regardless of weight and size has a very minimal risk of any complications and while it can be scary to hear a weight prediction that is far from normal, in most cases regression to the mean will help out. 
